# ðŸ’¬ InstructTTSEval

InstructTTSEval is a comprehensive benchmark designed to evaluate Text-to-Speech (TTS) systems' ability to follow complex natural-language style instructions. The dataset provides a hierarchical evaluation framework with three progressively challenging tasks that test both low-level acoustic control and high-level style generalization capabilities.

- Data available at [Huggingface](https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval)
- Paper: [InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems](https://arxiv.org/pdf/2506.16381)

## Citation
Please cite our paper if you find this work useful:
```bibtex
@misc{huang2025instructttsevalbenchmarkingcomplexnaturallanguage,
      title={InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems}, 
      author={Kexin Huang and Qian Tu and Liwei Fan and Chenchen Yang and Dong Zhang and Shimin Li and Zhaoye Fei and Qinyuan Cheng and Xipeng Qiu},
      year={2025},
      eprint={2506.16381},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2506.16381}, 
}
```
