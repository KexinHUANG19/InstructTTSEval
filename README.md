# ðŸ’¬ InstructTTSEval

InstructTTSEval is a comprehensive benchmark designed to evaluate Text-to-Speech (TTS) systems' ability to follow complex natural-language style instructions. The dataset provides a hierarchical evaluation framework with three progressively challenging tasks that test both low-level acoustic control and high-level style generalization capabilities.

- Data available at [Huggingface](https://huggingface.co/datasets/CaasiHUANG/InstructTTSEval)
- Paper: [InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems]()

## Citation
Please cite our paper if you find this work useful:
```bibtex
@article{huang2024instructttseval,
  title={INSTRUCTTTSEVAL: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems},
  author={Huang, Kexin and Tu, Qian and Fan, Liwei and Yang, Chenchen and Zhang, Dong and Li, Shimin and Fei, Zhaoye and Cheng, Qinyuan and Qiu, Xipeng},
  journal={arXiv preprint arXiv:xxxx.xxxxx},
  year={2025}
}
```
